# üìö docs-crawler

*Scripts Python pour exporter le contenu d‚Äôun site Confluence interne (pages + PDF) et crawler un site Docktail afin de rapatrier tous les documents (HTML, PDF, Office‚Ä¶).*

---

## Sommaire
1. [Fonctionnalit√©s](#fonctionnalit√©s)
2. [Pr√©requis](#pr√©requis)
3. [Installation](#installation)
4. [Configuration](#configuration)
5. [Ex√©cution rapide](#ex√©cution-rapide)
6. [D√©tails des scripts](#d√©tails-des-scripts)
7. [Trucs & Astuces](#trucs--astuces)
8. [Licence](#licence)

---

## Fonctionnalit√©s

| Script          | Objectif principal                                                                                              |
|-----------------|------------------------------------------------------------------------------------------------------------------|
| **`confluence.py`** | ‚Ä¢ Exporte toutes les pages (_page_ & _blogpost_) d‚Äôun site Confluence en JSON + PDF <br>‚Ä¢ Filtre optionnel par pr√©fixe d‚Äôespace |
| **`crawler.py`**    | ‚Ä¢ Crawler r√©cursif d‚Äôun site prot√©g√© (auth Basic) <br>‚Ä¢ T√©l√©chargement intelligent des documents externes <br>‚Ä¢ Conversion et fusion PDF (optionnelles) |

---

## Pr√©requis

* Python 3.9+
* Linux ou WSL (libreoffice + chromium n√©cessaires)
* Packages : `pip install -r requirements.txt`  
  (voir contenu : **aiohttp, aiofiles, PyPDF2, pdfkit, bs4, pyppeteer, requests, pdfkit**, etc.)
* `wkhtmltopdf`, `libreoffice`, `chromium-browser` install√©s dans le PATH

---

## Installation

```bash
git clone https://github.com/<org>/docs-crawler.git
cd docs-crawler
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
```

---

## Configuration

Toutes les variables se font via **variables d‚Äôenvironnement** :

| Variable                     | Par d√©faut                    | Script          | Description                                              |
|------------------------------|-------------------------------|-----------------|----------------------------------------------------------|
| `CONFLUENCE_URL`             | `https://confluence.local`    | confluence.py   | URL racine de Confluence                                 |
| `CONFLUENCE_API_TOKEN`       | _(obligatoire)_               | confluence.py   | Jeton d‚ÄôAPI (Bearer)                                     |
| `EXPORT_BASE_DIR`            | `/repo/confluence`            | confluence.py   | R√©pertoire racine d‚Äôexport                               |
| `SPACE_KEY_FILTER`           | `""`                          | confluence.py   | Pr√©fixe d‚Äôespace (ex. `PROJ` ‚Üí n‚Äôexporte que PROJ*)      |
| `DOCKTAIL_USERNAME`          | _(obligatoire)_               | crawler.py      | Login Docktail (auth Basic)                              |
| `DOCKTAIL_PASSWORD`          | _(obligatoire)_               | crawler.py      | Password Docktail                                        |
| `saveDirectory`              | `./docs`                      | crawler.py      | Dossier de sortie du crawler                             |
| `baseURL`                    | `https://docktail.test.local` | crawler.py      | URL de d√©part du crawl                                   |
| `maxDepth`                   | `10`                          | crawler.py      | Profondeur maximale du crawl                             |

---

## Ex√©cution rapide

### Export Confluence

```bash
CONFLUENCE_API_TOKEN=xxx \
python confluence.py
# ‚Üí ./pages/*.json et ./pdfs/*.pdf remplis
```

### Crawl Docktail

```bash
DOCKTAIL_USERNAME=foo DOCKTAIL_PASSWORD=bar \
python crawler.py
# ‚Üí ./docs/<arborescence>/‚Ä¶ (HTML, documents, PDF fusionn√©s)
```

---

## D√©tails des scripts

### `confluence.py`

* Utilise l‚ÄôAPI REST v2 pour lister tous les contenus.
* T√©l√©charge le PDF via `/spaces/flyingpdf/pdfpageexport.action?pageId=‚Ä¶`.
* N‚Äô√©crit un fichier (JSON ou PDF) **que** si :
  * inexistant ;
  * ou horodatage diff√©rent (√©vite les re-downloads inutiles).
* Slugification ASCII s√ªre pour les noms de fichiers.

### `crawler.py`

* Lance un **Chromium headless** (pyppeteer) avec interception des requ√™tes.
* Gestion compl√®te des ressources : cache 1 h, suivi des redirects, exclusion des polices.
* Remplacement des <img> par data-URI base64 pour un HTML autonome.
* Conversion facultative Office / HTML ‚Üí PDF (+ fusion progressive par dossier).
* R√©silient (retries, timeouts, d√©filement auto, gestion routerLink Angular).

---

## Trucs & Astuces

* **Vitesse** : lancez plusieurs exports en parall√®le en changeant `SPACE_KEY_FILTER`.
* **D√©pannage login Docktail** : v√©rifier que la 2FA n‚Äôest pas activ√©e sur le compte.
* **Limites Confluence** : l‚ÄôAPI `/rest/api/space` renvoie max 10 000 espaces.  
  Utiliser un filtre si votre instance est tr√®s volumineuse.
* **Docker** : un `Dockerfile` minimal est fourni, permet un run isol√© sans d√©pendances syst√®me.

---

## Licence

MIT ¬© 2025

---
